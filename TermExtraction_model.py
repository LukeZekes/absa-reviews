import spacy
import regex as re

from keras.models import Sequential, load_model
from keras.layers import Dense, Input
from keras.utils import to_categorical
from gensim.models.doc2vec import Doc2Vec
import numpy as np
from nltk.corpus import stopwords
from nltk.stem import SnowballStemmer
from nltk import word_tokenize
from extract_sentence_opinions import get_train_data, get_test_data, preprocess_text, generate_spans
from enum import IntEnum
nlp = spacy.load("en_core_web_md")
d2v = Doc2Vec.load("models/good/d2v.model")
loaded_train_data = get_train_data()
loaded_test_data = get_test_data()

# Model takes an input of a vector generated by the d2v model, and outputs a class 0, 1, or 2 (defined by the TermClasses enum)

class TermClasses(IntEnum):
  INVALID = 0
  ASPECT = 1
  OPINION = 2

def prep_data(data):
  max_span_len = 5
  prepped_data = []
  for entry in data:
    sentence = entry["sentence"]
    aspect_tags = entry["aspect_terms"]
    opinion_tags = entry["opinion_terms"]
    sentence_spans = {
      'sentence': sentence,
      'spans': []
    }
    # Get all spans and their classes
    span_texts = generate_spans(sentence, max_span_len)
    spans = [[t, int(TermClasses.INVALID)] for t in span_texts]
    for span in spans:
      # Classify each span
      if span[0] in aspect_tags: 
        span[1] = int(TermClasses.ASPECT)
      elif span[0] in opinion_tags:
        span[1] = int(TermClasses.OPINION)
    sentence_spans["spans"] = spans
    prepped_data.append(sentence_spans)

  return prepped_data


# Create input and output sets from data
train_data = prep_data(loaded_train_data)
train_input = []
train_output = []
for item in train_data:
  for span in item["spans"]:
    train_input.append(d2v.infer_vector(span[0].split()))
    train_output.append(span[1])

train_input = np.array(train_input)
train_output = to_categorical(np.array(train_output), 3)

test_data = prep_data(loaded_test_data)
test_input = []
test_output = []
for item in test_data:
  for span in item["spans"]:
    test_input.append(d2v.infer_vector(span[0].split()))
    test_output.append(span[1])

test_input = np.array(test_input)
test_output = to_categorical(np.array(test_output), 3)

# Create model
model = Sequential()
model.add(Dense(64, activation="relu", input_shape=(100, )))
model.add(Dense(32, activation='relu'))
model.add(Dense(3, activation='softmax'))

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.fit(x=train_input, y=train_output, validation_data=(test_input, test_output), epochs=4)
model.save("models/ATE/good")